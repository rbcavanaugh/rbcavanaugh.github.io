---
title: "Visualizing the 2016, 2020, and 2022 Aphasia Awareness Surveys"
author:
  - name: Rob Cavanaugh
    url: {}
date: 2022-06-27
draft: false
preview: preview.png
creative_commons: CC BY-NC
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

The National Aphasia Association (NAA) recently released [an update to their aphasia 
awareness survey](https://www.aphasia.org/2022-aphasia-awareness-survey/), in response to the recent news of Bruce Willis' aphasia diagnosis. 

>We typically conduct this survey every four years but decided to alter the schedule in view of the recent media coverage of aphasia, following the announcement by the Willis family.

The NAA's post nicely shows the responses for 2022 and provides a narrative description
for how the responses changed in response to 2022. I thought it might be helpful to 
also visualize changes in survey responses across the three survey years (2016, 2020, and 2022). The following figures and tables attempt to show visually some of the
narrative comparisons from the NAA blog post. 

```{r, warning = FALSE, message = FALSE}
# load packages needed
library(tidyverse)
library(readxl)
library(ggiraph)
library(tidytext)

# cleaning script for the three survey files
# cleans the files and removes all but the final file
# also aved in the _posts directory
source(here::here("_posts", "2022-06-25-aphasia-access-awareness-survey", "aphasia-access-awareness-survey.R"))

# hex codes
aablue = "#517cb6"
aagreen = "#03bf6f"
aayellow = "#f9be00"
aateal = "#6bc8cc"
aaorange = "#ff8b4f"
aapurple = "#7d5e90"


```

<br>

```{r}

s1 = data_all %>%
  add_count(year, name = "respondents") %>%
  group_by(year, q_heard_of, respondents) %>%
  summarize(heard_term = n()/mean(respondents)) %>%
  mutate(q_heard_of = factor(q_heard_of, levels = c("Yes", "No"))) %>%
  ggplot(aes(x = year, y = heard_term, fill = q_heard_of)) +
  geom_col(position = position_dodge(),  width = 0.8, color = "black", alpha = 0.8) +
  scale_fill_manual(values = c(aagreen, aablue)) +
  labs(title = str_wrap("Have you ever heard the term aphasia?"),
       y = "Percentage of Respondents", 
       x = "Year") +
  geom_text(size = 3, aes(label = scales::percent(heard_term)), vjust = -0.5, position = position_dodge(0.8)) +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(s1), height_svg = 4)

```


```{r}
s2 = data_all %>%
  add_count(year, name = "respondents") %>%
  group_by(year, q_heard_of, respondents, q_describes) %>%
  summarize(heard_term = n()/mean(respondents)) %>%
  filter(q_describes == "A language disorder") %>%
  mutate(not_heard_term = 1-heard_term) %>%
  pivot_longer(cols = c(heard_term:not_heard_term), names_to = "which", values_to = "percentage") %>%
  mutate(q_heard_of = ifelse(which == "heard_term", "Aphasia aware", "Not aphasia aware"),
         q_heard_of = factor(q_heard_of, levels = c("Aphasia aware", "Not aphasia aware"))) %>%
  ggplot(aes(x = year, y = percentage, fill = q_heard_of)) +
  geom_col(position = position_dodge(),   width = 0.8, color = "black", alpha = 0.8) +
  scale_fill_manual(values = c(aagreen, aablue)) +
  labs(title = str_wrap("Respondents who had heard of aphasia & could identify it as a language disorder"),
       y = "Percentage of Respondents", 
       x = "Year") +
  geom_text(size = 3, aes(label = scales::percent(percentage)), vjust = -0.5, position = position_dodge(0.8)) +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(s2), height_svg = 4)

```

```{r}
levels = c("None of the above", "A heart condition",  "A circulatory condition", 
           "A language disorder", "A spinal condition", "I'm not sure")

p1 = data_all %>%
  add_count(year, name = "respondents") %>%
  group_by(year, respondents) %>%
  count(q_describes) %>%
  drop_na(q_describes) %>%
  group_by(year) %>%
  mutate(percentage = n / sum(n),
         q_describes = factor(q_describes, levels = levels ),
         percent = scales::percent(percentage)) %>%
  ggplot(aes(x = year, y = percentage, fill = q_describes)) +
  geom_col_interactive(aes(tooltip = percent, group = q_describes), alpha=0.8 ,  colour="black", width = 0.5) +
  scale_fill_manual(values = c(aagreen, aablue, aayellow, aateal, aaorange, aapurple)) +
  labs(title = "Which of the following best describes aphasia?",
       y = "Percentage of Respondents", 
       x = "Year") +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(p1), height_svg = 4)
```

```{r}
p2 = data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0)) %>%
  filter(aware==1) %>%
  add_count(year, name = "respondents") %>%
  mutate(personal = ifelse(!is.na(q_know_someone_else), q_know_someone_else, q_know_someone)) %>%
  group_by(year, respondents, personal) %>%
  summarize(percentage = n()/mean(respondents, na.rm = T)) %>%
  mutate(personal = factor(personal, levels = c("Yes", "No", "I don't know"))) %>%
  ggplot(aes(x = year, y = percentage, fill = personal)) +
  geom_col(position = position_dodge(),  width = 0.8, color = "black", alpha = 0.8) +
  scale_fill_manual(values = c(aagreen, aablue, aayellow)) +
  labs(title = "Do you know someone who has been diagnosed with aphasia?",
       y = "Percentage of Respondents", 
       x = "Year") +
  geom_text(size = 3, aes(label = scales::percent(percentage)), vjust = -0.5, position = position_dodge(0.8)) +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(p2) , height_svg = 4)

```

```{r}
levels = c("strongly disagree", "somewhat disagree", "neutral", "somewhat agree",
           "strongly agree")

p3 = data_all %>%
  mutate(q_intellect = tolower(q_intellect)) %>%
  add_count(year, name = "respondents") %>%
  group_by(year, respondents) %>%
  count(q_intellect) %>%
  drop_na(q_intellect) %>%
  group_by(year) %>%
  mutate(percentage = n / sum(n),
         q_intellect = factor(q_intellect, levels = levels ),
         percent = scales::percent(percentage)) %>%
  ggplot(aes(x = year, y = percentage, fill = q_intellect)) +
  geom_col_interactive(aes(tooltip = percent, group = q_intellect),alpha=0.8 ,  colour="black", width = 0.5) +
  scale_fill_manual(values = c(aagreen, aablue, aayellow, aateal, aaorange, aapurple)) +
  labs(title = str_wrap("To what extent do you agree with the following statement? If a person
                has difficulty with speech, it means they also have intellectual
                difficulties."),
       y = "Percentage of Respondents", 
       x = "Year") +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(p3) , height_svg = 4)

```

```{r}

p4 = data_all %>%
  add_count(year, name = "respondents") %>%
  group_by(year, respondents) %>%
  count(q_common_cva) %>%
  drop_na(q_common_cva) %>%
  group_by(year) %>%
  mutate(percentage = n / sum(n),
         q_common_cva = factor(q_common_cva, levels = c("Yes", "No", "I don't know")),
         percent = scales::percent(percentage)) %>%
  ggplot(aes(x = year, y = percentage, fill = q_common_cva)) +
  geom_col_interactive(aes(tooltip = percent, group = q_common_cva),alpha=0.8 ,  colour="black", width = 0.5) +
  scale_fill_manual(values = c(aagreen, aablue, aayellow)) +
  labs(title = str_wrap("Is it common for a person who has had a stroke or brain injury
                        to have difficulties with speech and communication?"),
       y = "Percentage of Respondents", 
       x = "Year") +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(p4) , height_svg = 4)

```


```{r}

levels = c("From a doctor",
           "On TV or in a movie", 
           "From a family member or friend",
           "In a newspaper, magazine or online publication",
           "I don't recall",
           "Other (please specify)")
p5 = data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         q_first_heard = ifelse(str_detect(q_first_heard, "Other"), "Other (please specify)", q_first_heard),
         q_first_heard = factor(q_first_heard, levels = levels)) %>%
  filter(aware==1) %>%
  add_count(year, name = "respondents") %>%
  group_by(year, respondents, q_first_heard) %>%
  summarize(percentage = n()/mean(respondents, na.rm = T),
         percent = scales::percent(percentage)) %>%
  # mutate(q_first_heard = factor(q_first_heard, levels = c("Yes", "No", "I don't know"))) %>%
  ggplot(aes(x = year, y = percentage, fill = q_first_heard)) +
  geom_col_interactive(aes(tooltip = percent, group = q_first_heard),alpha=0.8 ,  colour="black", width = 0.5) +
  scale_fill_manual(values = c(aagreen, aablue, aayellow, aateal, aaorange, aapurple)) +
  labs(title = "If you can recall, where do you think you first heard about aphasia?",
       y = "Percentage of Respondents", 
       x = "Year") +
  theme_classic(base_size = 9) + 
    scale_y_continuous(labels = scales::label_percent(), limits = c(0, 1),
                       expand = expansion(mult = c(0, 0.05))) +
  theme(legend.title = element_blank(), plot.title.position = "plot",
        legend.position = "bottom")

girafe(code = print(p5) , height_svg = 4)

```


<br>


```{r panelset, echo=FALSE}
xaringanExtra::use_panelset()
```


The NAA used word clouds to show common responses to the question, 
"Where was the last place you recall reading or hearing about aphasia?"

![Figure reprinted from https://www.aphasia.org/2022-aphasia-awareness-survey/](https://www.aphasia.org/wp-content/uploads/2022/05/Screen-Shot-2022-05-07-at-2.06.17-PM.png){width=100% .external}    


To provide easy comparison, I calculate the most common words, bigrams (adjacent two-word combinations), and trigrams (adjacent three-word combinations) by year. These tables
can be searched, filtered, or sorted by year, the number of mentions, and word/bigram/trigram.

<br>

::::: {.panelset}

::: {.panel}

## Words {.panel-name}

```{r}


data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         id = row_number(),
         q_last_place = iconv(q_last_place, from = "latin1", to = "ASCII", sub = ""),
         q_last_place = gsub("[[:punct:]]+", "", q_last_place)
         ) %>%
  filter(aware == 1) %>%
  select(year, id, q_last_place) %>%
  unnest_tokens(word, q_last_place) %>%
  filter(!word %in% stop_words$word) %>%
  count(year, word, sort = TRUE, name = "Number of Mentions") %>%
  drop_na(word) %>%
  mutate(year = as.factor(year)) %>%
  rename(Year = year, Word = word) %>%
  DT::datatable(filter = 'top', rownames = FALSE,
                options = list(pageLength = 5))

```

:::

::: {.panel}

## Bigrams {.panel-name}

```{r}

data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         id = row_number(),
         q_last_place = iconv(q_last_place, from = "latin1", to = "ASCII", sub = ""),
         q_last_place = gsub("[[:punct:]]+", "", q_last_place)) %>%
  filter(aware == 1) %>%
  select(year, id, q_last_place) %>%
  drop_na(q_last_place) %>%
  unnest_tokens(tokens, q_last_place, token = "ngrams", n = 2) %>%
  separate(tokens, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  group_by(year) %>%
  count(word1, word2, sort = TRUE, name = "Number of Mentions") %>%
  drop_na(word1, word2) %>%
  unite(Bigram, word1, word2, sep = " ") %>%
  mutate(year = as.factor(year)) %>%
  rename(Year = year) %>%
  DT::datatable(filter = 'top', rownames = FALSE,
                options = list(pageLength = 5))
```

:::

::: {.panel}

## Trigrams {.panel-name}

```{r}

data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         id = row_number(),
         q_last_place = iconv(q_last_place, from = "latin1", to = "ASCII", sub = ""),
         q_last_place = gsub("[[:punct:]]+", "", q_last_place)) %>%
  filter(aware == 1) %>%
  select(year, id, q_last_place) %>%
  drop_na(q_last_place) %>%
  unnest_tokens(tokens, q_last_place, token = "ngrams", n = 3) %>%
  separate(tokens, c("word1", "word2", "word3"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word3 %in% stop_words$word) %>% 
  group_by(year) %>%
  count(word1, word2, word3, sort = TRUE, name = "Number of Mentions") %>%
  drop_na(word1, word2, word3) %>%
  unite(Trigram, word1, word2, word3, sep = " ") %>%
  mutate(year = as.factor(year)) %>%
  rename(Year = year) %>%
  DT::datatable(filter = 'top', rownames = FALSE,
                options = list(pageLength = 5))

```

:::

:::::


The survey also asked, "In your own words, how does aphasia affect the afflicted 
person?". To summarize the key words and phrases respondents used to describe aphasia
I also summarized the most frequent words, bigrams and trigrams. Note that these are
only for participants who the NAA considered *aphasia aware* in that they reported they
had heard the term aphasia and could properly identify it as a language disorder.

<br>

::::: {.panelset}

::: {.panel}

## Words {.panel-name}

```{r}

data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         id = row_number(),
         q_own_words = iconv(q_own_words, from = "latin1", to = "ASCII", sub = ""),
         q_own_words = gsub("[[:punct:]]+", "", q_own_words)
         ) %>%
  filter(aware == 1) %>%
  select(year, id, q_own_words) %>%
  unnest_tokens(word, q_own_words) %>%
  filter(!word %in% stop_words$word) %>%
  count(year, word, sort = TRUE, name = "Number of Mentions") %>%
  drop_na(word) %>%
  mutate(year = as.factor(year)) %>%
  rename(Year = year, Word = word) %>%
  DT::datatable(filter = 'top', rownames = FALSE,
                options = list(pageLength = 5))

```

:::

::: {.panel}

## Bigrams {.panel-name}

```{r}

data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         id = row_number(),
         q_own_words = iconv(q_own_words, from = "latin1", to = "ASCII", sub = ""),
         q_own_words = gsub("[[:punct:]]+", "", q_own_words)) %>%
  filter(aware == 1) %>%
  select(year, id, q_own_words) %>%
  drop_na(q_own_words) %>%
  unnest_tokens(tokens, q_own_words, token = "ngrams", n = 2) %>%
  separate(tokens, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  group_by(year) %>%
  count(word1, word2, sort = TRUE, name = "Number of Mentions") %>%
  drop_na(word1, word2) %>%
  unite(Bigram, word1, word2, sep = " ") %>%
  mutate(year = as.factor(year)) %>%
  rename(Year = year) %>%
  DT::datatable(filter = 'top', rownames = FALSE,
                options = list(pageLength = 5))
```

:::

::: {.panel}

## Trigrams {.panel-name}

```{r}

data_all %>%
  mutate(aware = ifelse(q_heard_of == "Yes" & str_detect(q_describes, "language"), 1, 0),
         id = row_number(),
         q_own_words = iconv(q_own_words, from = "latin1", to = "ASCII", sub = ""),
         q_own_words = gsub("[[:punct:]]+", "", q_own_words)) %>%
  filter(aware == 1) %>%
  select(year, id, q_own_words) %>%
  drop_na(q_own_words) %>%
  unnest_tokens(tokens, q_own_words, token = "ngrams", n = 3) %>%
  separate(tokens, c("word1", "word2", "word3"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  filter(!word3 %in% stop_words$word) %>% 
  group_by(year) %>%
  count(word1, word2, word3, sort = TRUE, name = "Number of Mentions") %>%
  drop_na(word1, word2, word3) %>%
  unite(Trigram, word1, word2, word3, sep = " ") %>%
  mutate(year = as.factor(year)) %>%
  rename(Year = year) %>%
  DT::datatable(filter = 'top', rownames = FALSE,
                options = list(pageLength = 5))

```

:::

:::::


Overall, it does appear that general awareness of aphasia changed after Bruce Willis'
diagnosis of aphasia and could reasonably be attributed to the publicity surrounding
his diagnosis. It will be interesting to see whether this increased awareness persist
over time. 

Here's the summary from the NAA: 

> This aphasia awareness numbers that we see in the 2022 survey are much higher than we saw in previous surveys, and more recently, in the 2020 survey. More importantly, we’re seeing a higher percentage of people that have heard of aphasia able to properly identify it as a language disorder and understand that loss of language does not mean loss of intellect.

> As more public figures are diagnosed with Aphasia, like Bruce Willis, Emilia Clarke, Gabby Giffords and so on, it’s important to help the public better understand aphasia and know where they can get aphasia resources.


R code for cleaning, combining and visualizing survey responses can be found 
on github here: https://github.com/rbcavanaugh/personal-website-distill/tree/master/_posts/2022-06-25-aphasia-access-awareness-survey. There is an R-script for cleaning the three survey
documents. The code for producing figures is in the .Rmd file. 

If you have any suggestions for changes or additions,
please don't hesitate to reah out via [email](mailto:rob.cavanaugh@pitt.edu) or [twitter](https://twitter.com/littlejohnsband). 



